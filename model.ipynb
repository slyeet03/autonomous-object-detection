{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# â Autonomous Object Detection System\n",
        "Problem Statement\n",
        "Object detection is crucial for autonomous systems such as self-driving cars and surveillance.\n",
        "This project builds a real-time object detection system using deep learning.\n"
      ],
      "metadata": {
        "id": "mfmZXEAKYwfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "eQUsxhgzYzO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import os\n",
        "import kagglehub\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "aii9M_cmY1VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU Check"
      ],
      "metadata": {
        "id": "LlFdGeX7MU14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "XeMi0kVpMcPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shit we will be using\n",
        "- Framework: Tensorflow\n",
        "- Model: SSD MobileNet\n",
        "- Dataset: COCO128\n",
        "\n",
        "Resources used\n",
        "- Youtube: codebasics, DeepBeaning\n",
        "- v7labs.com\n",
        "- and ofcourse heavy use of ChatGPT"
      ],
      "metadata": {
        "id": "aS0MqhrrN5QD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle Creds"
      ],
      "metadata": {
        "id": "bhHoe9v-QmnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_USERNAME')"
      ],
      "metadata": {
        "id": "AYucbfF3QogQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the classes by COCO"
      ],
      "metadata": {
        "id": "LudhCNSAfZzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COCO_CLASSES = [\n",
        "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
        "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',\n",
        "    'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
        "    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
        "    'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',\n",
        "    'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]"
      ],
      "metadata": {
        "id": "M8rZztaIfc_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters\n"
      ],
      "metadata": {
        "id": "wZPZZwNK5Ln2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GRID_SIZE = 13\n",
        "BOXES_PER_CELL = 3\n",
        "NUM_CLASSES = 80\n",
        "INPUT_SIZE = 416\n",
        "CELL_SIZE = 32"
      ],
      "metadata": {
        "id": "QYFAaS5u5QFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset"
      ],
      "metadata": {
        "id": "gCPcUgkDOyrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"ultralytics/coco128\")\n",
        "\n",
        "print(path)\n",
        "print(os.listdir(path))"
      ],
      "metadata": {
        "id": "HE7wjqRgO6yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_DIR = os.path.join(path, \"coco128\",\"images\", \"train2017\")\n",
        "LABEL_DIR = os.path.join(path, \"coco128\",\"labels\",\"train2017\")"
      ],
      "metadata": {
        "id": "X2qAFDGPTgZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"images: \",len(os.listdir(IMG_DIR)))\n",
        "print(\"labels: \",len(os.listdir(LABEL_DIR)))"
      ],
      "metadata": {
        "id": "kKAuo7AWTxkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the image and label in sorted pairs"
      ],
      "metadata": {
        "id": "qqCyUwSSXXYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_files = sorted(os.listdir(IMG_DIR))\n",
        "label_files = sorted(os.listdir(LABEL_DIR))"
      ],
      "metadata": {
        "id": "vvXLaz4OXGT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading an image and drawing bounding boxes around it"
      ],
      "metadata": {
        "id": "CSspEvwAY19r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_label(index):\n",
        "  # picking nth image\n",
        "  image_name = image_files[index]\n",
        "  label_name = label_files[index]\n",
        "\n",
        "  # loading the image\n",
        "  img_path = os.path.join(IMG_DIR, image_name)\n",
        "  img = cv2.imread(img_path)\n",
        "\n",
        "  if img is None:\n",
        "    print(f\"no image at {img_path}\")\n",
        "    return None, None, None, None, None,\n",
        "\n",
        "  height, width, channels = img.shape\n",
        "\n",
        "  # reading the label file\n",
        "  with open(os.path.join(LABEL_DIR, label_name), 'r') as f:\n",
        "    labels = f.readlines()\n",
        "\n",
        "  return image_name, img, labels, height, width\n"
      ],
      "metadata": {
        "id": "oNEjyF7XZBIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_bb(label, width, height):\n",
        "  parts_string = label.split()\n",
        "  parts = [float(x) for x in parts_string]\n",
        "\n",
        "  # convert label data to data for bb in pixels\n",
        "  class_id = int(parts[0])\n",
        "  x_center = float(parts[1]) * width\n",
        "  y_center = float(parts[2])*height\n",
        "  box_width = float(parts[3])*width\n",
        "  box_height = float(parts[4])*height\n",
        "\n",
        "  # convert center coord to corner coord to draw bb\n",
        "  # top left\n",
        "  x1 = x_center-(box_width/2)\n",
        "  y1 = y_center-(box_height/2)\n",
        "  # bottom right\n",
        "  x2 = x_center+(box_width/2)\n",
        "  y2 = y_center+(box_height/2)\n",
        "\n",
        "  return class_id, int(x1), int(y1), int(x2), int(y2)"
      ],
      "metadata": {
        "id": "Q2FhIINqblXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bb(index):\n",
        "  image_name, img, labels, height, width = load_image_label(index)\n",
        "\n",
        "  img_bb = img.copy()\n",
        "\n",
        "  for label in labels:\n",
        "    class_id, x1, y1, x2, y2 = label_to_bb(label, width, height)\n",
        "    class_name = COCO_CLASSES[class_id]\n",
        "\n",
        "    # random color for the bb\n",
        "    color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
        "\n",
        "    img_bb = cv2.rectangle(img, (x1,y1), (x2,y2), color, 2)\n",
        "    img_bb = cv2.putText(img_bb, class_name, (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.imshow(cv2.cvtColor(img_bb, cv2.COLOR_BGR2RGB))\n",
        "  plt.axis('off')\n",
        "  plt.title(f\"{image_name} - {len(labels)} objects\")\n",
        "  plt.show()\n",
        "\n",
        "  return img_bb\n"
      ],
      "metadata": {
        "id": "v12_Wp18ePVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Image and Label"
      ],
      "metadata": {
        "id": "fMw_EJ4Pj-MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "  resize_img = cv2.resize(img, (INPUT_SIZE,INPUT_SIZE), interpolation=cv2.INTER_LINEAR)\n",
        "  normalized_img = resize_img / 255.0\n",
        "\n",
        "  return normalized_img\n"
      ],
      "metadata": {
        "id": "P01yZyTskhWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_labels(labels):\n",
        "    processed = []\n",
        "    for label in labels:\n",
        "        parts = label.strip().split()\n",
        "        # class_id, x_center, y_center, width, height\n",
        "        parsed = [float(parts[0])] + [float(x) for x in parts[1:]]\n",
        "        processed.append(parsed)\n",
        "\n",
        "    return processed\n"
      ],
      "metadata": {
        "id": "99JOkz52qpSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Creation"
      ],
      "metadata": {
        "id": "M_yDj8KkkuCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset():\n",
        "  preprocessed_images = []\n",
        "  preprocessed_labels = []\n",
        "\n",
        "  print(f\"processing {len(image_files)} images...\")\n",
        "\n",
        "  for i in range(len(image_files)):\n",
        "    image_name, img, labels, height, width = load_image_label(i)\n",
        "\n",
        "    preprocessed_img = preprocess_image(img)\n",
        "    processed_labels = preprocess_labels(labels)\n",
        "\n",
        "    preprocessed_images.append(preprocessed_img)\n",
        "    preprocessed_labels.append(processed_labels)\n",
        "\n",
        "  print(f\"Total images: {len(preprocessed_images)}\")\n",
        "  print(f\"Total labels: {len(preprocessed_labels)}\")\n",
        "\n",
        "  return preprocessed_images, preprocessed_labels"
      ],
      "metadata": {
        "id": "gfbeENsGl7BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(images,labels,train_ratio=0.8):\n",
        "  split_index = int(len(images)*train_ratio)\n",
        "\n",
        "  train_images = images[:split_index]\n",
        "  train_labels = labels[:split_index]\n",
        "  val_images = images[split_index+1:]\n",
        "  val_labels = labels[split_index:]\n",
        "\n",
        "  return train_images, train_labels, val_images, val_labels"
      ],
      "metadata": {
        "id": "0scuu_2MrAth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid based label"
      ],
      "metadata": {
        "id": "qjdRIj8a2xnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_grid_labels(labels):\n",
        "  y=[]\n",
        "\n",
        "  for label in labels:\n",
        "    # empty grid\n",
        "    grid = np.zeros((GRID_SIZE,GRID_SIZE,BOXES_PER_CELL,NUM_CLASSES+5))\n",
        "    # no of bb per grid\n",
        "    cell_bb_count = np.zeros((GRID_SIZE,GRID_SIZE), dtype=int)\n",
        "\n",
        "    for obj in label:\n",
        "      class_id = int(obj[0])\n",
        "      x_center = float(obj[1])\n",
        "      y_center = float(obj[2])\n",
        "      width = float(obj[3])\n",
        "      height = float(obj[4])\n",
        "\n",
        "      # grid the object is in\n",
        "      grid_x=int(x_center*GRID_SIZE)\n",
        "      grid_y=int(y_center*GRID_SIZE)\n",
        "      # if coord is 1 then the grid becomes 13 and bam out of bounds error\n",
        "      grid_x=min(grid_x,GRID_SIZE-1)\n",
        "      grid_y=min(grid_y,GRID_SIZE-1)\n",
        "\n",
        "      # checking whether the grid has room for another bb\n",
        "      cell_count_current = cell_bb_count[grid_y,grid_x]\n",
        "\n",
        "      if cell_count_current>=BOXES_PER_CELL:\n",
        "        # if max(=3) objects reached then skip object\n",
        "        print(f\"({grid_y,{grid_x}}) full, skipping obejct\")\n",
        "        continue\n",
        "\n",
        "      # calculating where in the cell the object is instead of the whole ass image\n",
        "      # absolute pos in form of grid\n",
        "      x_abs=x_center*GRID_SIZE\n",
        "      y_abs=y_center*GRID_SIZE\n",
        "      # pos within the cell\n",
        "      x_rel=x_abs-grid_x\n",
        "      y_rel=y_abs-grid_y\n",
        "\n",
        "      # using one hot encoding to not confuse this dumb aah model\n",
        "      class_one_hot = np.zeros(NUM_CLASSES)\n",
        "      class_one_hot[class_id] = 1.0\n",
        "\n",
        "      bbox = np.array([x_rel,y_rel,width,height])\n",
        "      # if confidence 1 then object there\n",
        "      # putting confidence manually so the model can filter empty cells\n",
        "      confidence = np.array([1.0])\n",
        "\n",
        "      label = np.concatenate([class_one_hot,bbox,confidence])\n",
        "      # assinging that label to the grid it corresponds to\n",
        "      grid[grid_y, grid_x, cell_count_current]=label\n",
        "      # mark that grid used\n",
        "      cell_bb_count[grid_y,grid_x] += 1\n",
        "\n",
        "    y.append(grid)\n",
        "\n",
        "  return np.array(y)\n"
      ],
      "metadata": {
        "id": "9uTIR2N7218l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function"
      ],
      "metadata": {
        "id": "aucufZUM8ad7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_detection_loss(y_true, y_pred):\n",
        "  # will combine three losses\n",
        "  # is it the right object, is the box in the right place, is there an object\n",
        "\n",
        "  # seperating the classes -> 0-79: class, 80-83: bb data, 84: confidence\n",
        "  y_true_class = y_true[..., :NUM_CLASSES]\n",
        "  y_pred_class = y_pred[..., :NUM_CLASSES]\n",
        "  y_true_bb = y_true[..., NUM_CLASSES:NUM_CLASSES+4]\n",
        "  y_pred_bb = y_pred[..., NUM_CLASSES:NUM_CLASSES+4]\n",
        "  y_true_conf = y_true[..., -1:]\n",
        "  y_pred_conf = y_pred[..., -1:]\n",
        "\n",
        "  # having a mask matrix same as conf matrix which we can multiply later so that empty grid would not be calculated\n",
        "  obj_mask = y_true_conf\n",
        "\n",
        "  class_loss = keras.losses.categorical_crossentropy(y_true_class, y_pred_class)\n",
        "  class_loss = class_loss * tf.squeeze(obj_mask, axis=-1)\n",
        "  class_loss = tf.reduce_mean(class_loss)\n",
        "\n",
        "  bb_loss = tf.reduce_mean(tf.square(y_true_bb-y_pred_bb),axis=-1,keepdims=True)\n",
        "  bb_loss = bb_loss*obj_mask\n",
        "  bb_loss = tf.reduce_mean(bb_loss)\n",
        "\n",
        "  conf_loss = keras.losses.binary_crossentropy(y_true_conf, y_pred_conf)\n",
        "  conf_loss = tf.reduce_mean(conf_loss)\n",
        "\n",
        "  # adding weights\n",
        "  total_loss = class_loss + 5.0*bb_loss + conf_loss\n",
        "\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "o7xEl81n8b5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the model"
      ],
      "metadata": {
        "id": "6APWob3RsH2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = keras.applications.MobileNetV2(\n",
        "    input_shape = (INPUT_SIZE,INPUT_SIZE,3),\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    alpha=1.0\n",
        ")\n",
        "\n",
        "backbone.trainable = False"
      ],
      "metadata": {
        "id": "YvVv3ADcsI_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(INPUT_SIZE,INPUT_SIZE,3))\n",
        "\n",
        "layers = keras.layers\n",
        "\n",
        "x = backbone(inputs, training=False)\n",
        "\n",
        "x = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "\n",
        "num_outputs = BOXES_PER_CELL * (NUM_CLASSES + 5)\n",
        "\n",
        "outputs = layers.Conv2D(num_outputs, (1, 1), activation='sigmoid')(x)\n",
        "outputs = layers.Reshape((GRID_SIZE, GRID_SIZE, BOXES_PER_CELL, NUM_CLASSES + 5))(outputs)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "pHmifKDNuv2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "qzH_2AE_1Ptc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation"
      ],
      "metadata": {
        "id": "M8lFdfRFVOcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_images, all_labels = create_dataset()\n",
        "print(f\"Dataset created: {len(all_images)} images\")"
      ],
      "metadata": {
        "id": "iS3cTn5QVQPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train val split"
      ],
      "metadata": {
        "id": "IPYpe3OIVhZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs, train_labels, val_imgs, val_labels = train_val_split(all_images, all_labels, train_ratio=0.8)"
      ],
      "metadata": {
        "id": "q019T3JIVjWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to grid format"
      ],
      "metadata": {
        "id": "UjMCt4ajVygn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(train_imgs)\n",
        "x_val = np.array(val_imgs)\n",
        "y_train=prepare_grid_labels(train_labels)\n",
        "y_val=prepare_grid_labels(val_labels)\n",
        "\n",
        "print(f\"x_train: {x_train.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"x_val shape: {x_val.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")"
      ],
      "metadata": {
        "id": "IyOJVsfsWA8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile model"
      ],
      "metadata": {
        "id": "rQ6C2Q9GWqxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=grid_detection_loss,\n",
        "    metrics=['mae']\n",
        ")"
      ],
      "metadata": {
        "id": "w7dVq6YJWr03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "b6hoSlyXW6Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=0.00001,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "34OFtAFMW71W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=8,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "Zl65DaUuW_Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model"
      ],
      "metadata": {
        "id": "BZ0X4xEWXFrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('yolo_type_shi.h5')"
      ],
      "metadata": {
        "id": "QtLQlQ2qXGvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plots and shit"
      ],
      "metadata": {
        "id": "jnpQA9b0XNn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# loss plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Progress')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# MAE plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['mae'], label='Training MAE')\n",
        "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MAE')\n",
        "plt.title('Bounding Box Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KWjHOjG4XPNd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}